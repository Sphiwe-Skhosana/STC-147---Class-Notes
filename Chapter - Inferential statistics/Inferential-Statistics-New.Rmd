# Inferential Statistics

Statistical data analysis falls into two general categories: descriptive and inferential. **Descriptive statistics** comprises methods to describe and summarize the collected data using tables (e.g. frequency distribution), graphs (e.g. bar graph) and numbers (e.g. mean). These methods help us describe and, therefore, learn about the world around us.

The following scenarios involve descriptive statistics:

- A student wants to determine her average quiz score for the past 5 calculus quizzes.
- A student wants to know the percentage of classes he attended in which the lecture ended at exactly 20 minutes past the hour.
- A woman wants to know the variation in the dinner cooking time for the past five days.
- A teenager wants to know the daily average number of tik-tok posts that includes cats.

See Chapter \@ref(ch1) for more details about descriptive methods of statistical data analysis.

On the other hand, **inferential statistics**, which are the subject of this Chapter, involves methods for making generalizations, estimates or conclusions about some characteristic of the **population**, known as a **parameter**, using information from the collected data. Recall (from STC 137) that in most practical situations, it is impractical (e.g., surveying every citizen in a country) or impossible (e.g., testing every manufactured item) to collect data from the entire population. As a result, we collect data from a randomly selected subset of the population under study, known as a **sample** (see example in Figure \@ref(fig:sample). Based on this sample, we make statements or conclusions about the population under study.

\begin{figure}[h]
\centering
\includegraphics[width = 0.6\textwidth]{Figures/population_sample.png}
\caption{Illustration of a sample drawn from a population.}
\label{fig:sample}
\end{figure}

The following scenarios (analogous to the ones above) involve inferential statistics:

- A student wants to predict her calculus quiz score based on quiz scores from the previous 10 quizzes.
- Based on lecture time data from the previous 10 lecture sessions, a student wants to estimate the duration of today's lecture.
-Based on the cooking times from the first quarter of the year, a woman wants to estimate the variation in her second quarter cooking times.
- Based on information from 1000 tik-tok posts from last year, a teenager wants to predict the average number of posts that will feature cats next year. 

The main focus of this chapter is on giving a basic introduction to the main methods of inferential statistics that are useful in practice. As already mentioned at the beginning of Chapter \@ref(ch2), **probability** is important for developing and using inferential statistical methods. Probability can be seen as a bridge between descriptive and inferential statistics. Probability and statistics both deal with questions related to populations and samples but proceed in an "inverse manner" to each other:
- In a probability problem, properties of the population under study are assumed known and questions regarding a sample from the population are answered.
- In an inferential statistics problem, we start with the sample and make use of its properties to answer questions regarding the population from where the sample was taken.

Note that, due to **sampling error**, estimates based on one sample will differ from those based on another sample. Thus, there is a degree of uncertainty about the true population characteristics. Statistical inference (another phrase for inferential statistics) allows us to understand, quantify and report this uncertainty. 

## Statistical inference methods

### Point estimation
Suppose that $\theta$ is an unknown population parameter to be estimated. To estimate $\theta$, we collect a random sample of size $n$, denoted by $x_1,x_2,\dots,x_n$, from the population under study. Based on the sample, we calculate a corresponding characteristic of the sample called a sample **statistic**:

$$\hat{\theta}=h(x_1,x_2,\dots,x_n)$$
where $h(\cdot)$ is any function of the observed sample data that depends on the problem under study. For instance, if $\theta$ is the population average (mean), $\mu$, then 

$$h(x_1,x_2,\dots,x_n)=\bar{x}=\frac{\sum_{i=1}^nx_i}{n}$$
is the sample mean of the observed sample data.\\
The procedure to calculate $\hat{\theta}$ is called **point estimation** and the value of the sample statistic $\hat{\theta}$ is called the **point estimate** of $\theta$.  

### Interval estimation
The point estimate $\hat{\theta}$ alone does not give much information about the precision or reliability of the estimation of the population parameter $\theta$. In particular, without any additional information, we don't know how close $\hat{\theta}$ is to the true value of $\theta$. An alternative to reporting a single value for the parameter to be estimated is to calculate and report an interval of values, known as an **interval estimate** or **confidence interval**, likely to include the true value of the parameter $\theta$. The interval estimate is obtained by adding a value $\epsilon$, called the **margin of error**, to the point estimate

$$\hat{\theta}\pm \epsilon$$
$$(\hat{\theta}-\epsilon,\hat{\theta}+\epsilon)$$
The process of calculating an interval estimate is called **interval estimation**. There are two important concepts in interval estimation. First, the length of the interval, given by $2\epsilon$, which gives information about the precision of the interval estimate. Second, the **confidence level**, which measures the reliability of the interval estimate. If the confidence level is high and the resulting interval is quite narrow, our knowledge of the value of the parameter is reasonably precise. A very wide confidence interval, however, gives the message that there is a great deal of uncertainty concerning the value of what we are estimating. 

### Hypothesis testing

Frequently, the objective of statistical data analysis is not to estimate a parameter but to test whether a hypothetical statement about the parameter is true or false. For instance, a pharmaceutical company might be interested in knowing if a new drug is effective in treating a disease. Here, we have two hypothetical statements. The first one is that the drug is not effective. The second one is that the drug is effective. We denote these hypotheses as $H_0$ and $H_1$, respectively. The hypothesis $H_0$ is called the null hypothesis and the hypothesis $H_1$ is called the alternative hypothesis. The null hypothesis, $H_0$, is usually referred to as the default hypothesis, that is, the hypothesis that is initially assumed to be true. The alternative hypothesis, $H_1$, is the statement contradictory to $H_0$. Based on the observed data, we need to decide either to accept $H_0$, or to reject it, in which case we say we accept $H_1$. These are problems of **hypothesis testing**.\\  
As a practical example of hypothesis testing, consider the following scenario: A leading drug in the treatment of cancer has an advertised success rate of $84\%$. Lerato, a researcher, believes she has found a new drug, for treating cancer patients, that has a higher therapeutic success rate than the leading drug, but with fewer side effects. To test her assertion, she gets approval from the South African Health Products Regulatory Authority (SAHPRA) to conduct an experimental study involving a random sample of 60 cancer patients. The proportion of patients in the sample receiving therapeutic success will be used to determine if the success rate, $p$, for the population of cancer patients is higher than $0.84$. The researcher arbitrarily decides that she will conclude that the therapeutic success rate of the new drug is higher than $0.84$ if the proportion of cancer patients in the sample having therapeutic success after taking the drug is $0.86$ or higher. Otherwise, she will conclude that her drug is no more effective than the currently used drug. It appears, at first glance, that the decision should be clear-cutâ€”just compute the sample proportion, compare it to $0.84$, then make a decision. But the decision rests on the outcome of a single sample proportion, which will vary from sample to sample. If the true proportion in the population receiving therapeutic success is less than or equal to $0.84$ (i.e., if $p<0.84$), there is the possibility that $p$ could be greater than $0.86$, by chance, similarly, there is the possibility that the sample proportion could be less than $0.84$ even if the true proportion is, say, $0.87$. The uncertainty involving
the researchers decision can be attributed, in part, to the standard error of the sample proportion. The null and alternative hypotheses statements are

$$
H_0: p\leq 0.84\\
H_1: p>0.84
$$
There are two types of hypothesis. First, is the hypothesis that a researcher would like to establish called the research hypothesis or experimental hypothesis. This is the same as the alternative hypothesis. Second, is a claim